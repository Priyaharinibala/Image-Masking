{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def load_medical_images(data_path, image_size=(256, 256)):\n",
        "    image_list = []\n",
        "\n",
        "    for filename in os.listdir(data_path):\n",
        "        if filename.endswith(\".png\") or filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
        "            image_path = os.path.join(data_path, filename)\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, image_size)\n",
        "            img = img.astype(np.float32) / 255.0\n",
        "            image_list.append(img)\n",
        "    # Convert the list to a NumPy array\n",
        "    X_train = np.array(image_list)\n",
        "    return X_train\n",
        "\n",
        "# Example usage\n",
        "data_path = \"/content/drive/MyDrive/med_img\"\n",
        "X_train = load_medical_images(data_path)\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "\n",
        "\n",
        "# Function to build the VAE model\n",
        "def build_vae(input_shape, latent_dim):\n",
        "    # Encoder\n",
        "    encoder_inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    # Latent space\n",
        "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "\n",
        "    # Sampling layer\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = layers.Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
        "\n",
        "    # Build the encoder and decoder models\n",
        "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "    # Build the decoder model\n",
        "    decoder = build_decoder(latent_dim)\n",
        "\n",
        "    # VAE model\n",
        "    outputs = decoder(encoder(encoder_inputs)[2])\n",
        "    vae = keras.Model(encoder_inputs, outputs, name=\"vae\")\n",
        "\n",
        "    # Resize original images to match output dimensions\n",
        "    resized_encoder_inputs = layers.Lambda(lambda x: tf.image.resize(x, (64, 64)))(encoder_inputs)\n",
        "\n",
        "    # Define the VAE loss\n",
        "    \"\"\"reconstruction_loss = tf.keras.losses.binary_crossentropy(resized_encoder_inputs, outputs)\n",
        "    reconstruction_loss *= input_shape[0] * input_shape[1]  # Adjust for image size\n",
        "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "    kl_loss = tf.reduce_mean(kl_loss)\n",
        "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\"\"\"\n",
        "\n",
        "   # Define the VAE loss\n",
        "    reconstruction_loss = tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(resized_encoder_inputs),\n",
        "                                                          tf.keras.backend.flatten(outputs))\n",
        "    reconstruction_loss *= input_shape[0] * input_shape[1]  # Adjust for image size\n",
        "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "    kl_loss = tf.reduce_mean(kl_loss)\n",
        "    vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "\n",
        "    vae.add_loss(vae_loss)\n",
        "    vae.compile(optimizer=\"adam\")\n",
        "\n",
        "    return vae, encoder, decoder\n",
        "\n",
        "\n",
        "def build_decoder(latent_dim):\n",
        "    decoder_inputs = keras.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(16 * 16 * 64, activation=\"relu\")(decoder_inputs)\n",
        "    x = layers.Reshape((16, 16, 64))(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "    return keras.Model(decoder_inputs, decoder_outputs)\n",
        "\n",
        "# Function to display only the masked image\n",
        "def display_masked_image(masked):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    # Masked Image\n",
        "    plt.title(\"Masked Image\")\n",
        "    plt.imshow(np.squeeze(masked), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "display_masked_image(masked_image)\n",
        "\n",
        "# Function to display original and masked images\n",
        "def display_images(original, masked):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(np.squeeze(original), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Masked Image\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Masked Image\")\n",
        "    plt.imshow(np.squeeze(masked), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "#display_images(sample_image, masked_image)\n",
        "#print(\"Sample image shape:\", sample_image.shape)\n",
        "#print(\"Masked image shape:\", masked_image.shape)\n",
        "\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load medical images\n",
        "    data_path = \"/content/drive/MyDrive/med_img\"\n",
        "    X_train = load_medical_images(data_path)\n",
        "    print(X_train)\n",
        "    print(len(X_train))\n",
        "    print(X_train.shape)\n",
        "\n",
        "    # Build the VAE model\n",
        "    input_shape = (256, 256, 1)  # Adjust based on your image size and channels\n",
        "    latent_dim = 32  # Adjust based on your desired latent space dimension\n",
        "\n",
        "    # Training the VAE\n",
        "    vae, _, _ = build_vae(input_shape, latent_dim)\n",
        "    vae.fit(X_train, epochs=10, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Generate a masked image\n",
        "    sample_image = X_train[np.random.choice(len(X_train))]\n",
        "    sample_image = np.expand_dims(sample_image, axis=0)\n",
        "    masked_image = vae.predict(sample_image)\n",
        "\n",
        "    #display_masked_image(masked_image)\n",
        "    display_images(sample_image, masked_image)\n"
      ],
      "metadata": {
        "id": "v0Il4bWpCja6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}